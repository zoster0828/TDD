# 진화하는 아키텍처 토폴로지
* 아키텍트는 커플링을 필요악이라 매도하는 경우가 많다
* 최대한의 이득을 보는 적절한 수준의 커플링을 알아보자

## 5.1 진화 가능한 아키텍처 구조
* 진화성을 결정하는 핵심 동력 두 가지는 무엇일까
### 5.1.1 동조성
* 동조성 : 한 컴포넌트를 변경했을 때 시스템의 전반적인 정확성을 유지하기 위해 다른 컴포넌트를 수정해야 한다면
두 컴포넌트는 동조적이다

---
### 동조성의 두가지 정의
* 정적 동조성 : 소스 코드 수준에서 발생한다. 구조 설계에 정의된 구심 및 원심 커플링을 세분화한 개념이다
  * 명칭 동조성 : 복수의 컴포넌트가 특정 엔티티명에 동의한다
  * 타입 동조성 : 복수의 컴포넌트가 특정 엔티티 타입에 동의한다
  * 의미 동조성 , 관례 동조성 : 복수의 컴포넌트가 특정 값의 의미에 동의한다
  * 위치 동조성 : 복수의 컴포넌트가 특정 값의 순서에 동의한다
  * 알고리즘 동조성 : 복수의 컴포넌트가 특정 알고리즘에 동의한다
* 동적 동조성 : 런타임 시점에 호출 됨에 따라 발생한다
  * 실행 동조성 : 실행 순서가 복수의 컴포넌트에 영향을 미친다
  * 시점 동조성 : 실행 시점이 복수의 컴포넌트에 영향을 미친다
  * 값 동조성 : 서로 연관된 여러값이 함께 변경되어야 하는 경우
  * 식별 동조성 : 복수의 컴포넌트가 동일한 엔티티를 참조한다

* 동조성 속성
  * strength : 정적 > 동적, 명칭 > 타입 > 의미 > 알고리즘 > 위치 > 실행 > 시점 > 값 > 식별 순으로 동조성을 가져도 좋다
  * locality : 가까운 곳에 위치한 동조성은 멀리 있는 것 보다 낫다. 같은 동조성이라도 하나의 모듈에 있는것이 낫다
  * degree : 동조성의 영향을 미치는 클래스의 개수는 작을수록 좋다

* 시스템의 동조성을 개선하는 법
  1. 시스템을 세부 요소로 쪼개고 각각을 캡슐화 한다
  2. 캡슐화의 경계를 벗어나는 동조성을 최소화
  3. 캡슐화 경계 내부에서 동조성을 최대화
  4. 동조성을 제거하긴 어렵다 강도 낮은 동조성으로 변환
  5. 지역성의 원칙으로 요소 사이의 거리가 멀수록 약한 동조성을 사용

### 5.1.2 경계 콘텍스트와 동조성 교차
* DDD의 bounded context는 동조 지역성 개념과 유사하다
* 광범위한 커플링은 아키텍처를 연약하게 만드는 주범이다
* 상세구현 정보를 외부로 최소한으로 노출하고 경계에서는 이 변화들을 수용한다

## 5.2 아키텍처 퀀텀 및 세분성
* 아키텍처 퀀텀이란 높은 기능 응집도를 갖추고 독립적 배포가 가능한 컴포넌트이다

### 정적 & 동적 커플링
* 정적 : 아키텍처 내부에서 계약을 통해 정적 의존성을 해소하는 방식
  * 서비스가 서로 엮이는 방식을 묘사
  * 운영 의존성을 해석하는 수단
* 동적 : 퀀텀이 런타임에 동기 또는 비동기 통신을 주고받는 방식
  * 서비스가 런타임에 서로를 호출하는 방식을 묘사
  * 통신 의존성을 해석하는 수단

**워크플로 내부에 잘 배치된 마이크로 서비스는 그 자체로 아키텍처 퀀텀이라 할 수 있다**

### 5.2.1 독립 배포
* 독립 배포 가능 여부를 기준으로 보면 마이크로 서비스는 아키텍처 퀀텀이다
* 아키텍처 퀀텀을 기준으로 배포하면 생기는 이점
  * 경계는 아키텍트, 개발, 운영 사이에서 공통 언어의 역할을 한다
  * 분산 아키텍처에서 서비스의 세분성을 결정할 때 아키텍트가 고려해야 할 힘이 드러난다
  * 독립 배포를 위해서는 db와 같은 커플링 지점이 퀀텀 내부에 포함되어야 한다
    * > 어떤 장점이라는 건지 잘 모르겠음

### 5.2.2 고기능 응집도
* 고기능 응집도는 클래스, 컴포넌트, 서비스 등의 구조적 근접도를 나타낸다
* 독립 배포 관점에서 볼 때 거대한 모놀리식 아키텍처는 퀀텀으로 간주할 수 있다
  * 사실은 단순이 전부 가지고 있을 뿐 기능의 응집도는 낮다
* 이러한 고기능 응집도는 한 서비스가 다른 서비스에 얼마나 독립 또는 의존적인지를 나타내는 지표가 된다

### 5.2.3 강한 정적 커플링
* 아키텍처 퀀텀의 내부 요소가 서로 긴밀하게 엮여 있음을 의미한다
* 정적 커플링은 db까지 포함하므로 단일 db에 의존하는 시스템은 단일 퀀텀 이상을 보유할 수 없다
* 이경우 퀀텀 측정치는 1이 된다

---
* mediator 이벤트 기반 아키텍처 스타일은 단일 아키텍처 퀀텀으로 평가된다
* 분산 아키텍처 스타일을 묘사하나 요청 오케스트레이터와 db가 단일 아키텍처 퀀텀으로 만들어 버린다

---
* broker 이벤트 기반 아키텍처는 중재자가 없는 만큼 결합도가 더 낮다
* 그러나 모든 서비스가 단일 관계형 db를 활용해 공통 커플링 지점을 만듦에 따라 결국 1 퀀텀이 된다
  * 스스로 db를 쓰지 않아도 db를 쓰는 다른 서비스에 의존한다면 모두 아키텍처 퀀텀을 이루는 정적 커플링의 일부가 된다
---
* 각 서비스가 bounded context 역할을 하며 자신만의 아키텍처 특성을 보유하는 서비스가 있다고 가정해보자
  * 서비스의 갯수인 n 만큼의 n 퀀텀을 가지게 된다
* 그러나 사용자 인터페이스와 밀접하게 결합된다면 단일 퀀텀을 형성하기도 한다
  * 통상적으로 사용자 인터페이스는 fe와 be 사이에 커플링 지점을 만든다
  * 이러한 아키텍처는 설계도 어렵다, 성능, 확장성, 탄력성, 신뢰성 등의 특성을 서비스마다 다른 수준으로 설정하기 어렵기 때문이다
* 따라서 아키텍트는 fe와 be 사이에 커플링을 만들지 않는 async 방식으로 사용자 인터페이스를 설계한다

> 여러개의 화면을 모아서 browser에 뿌려주는 형태를 의미하는 듯함

### 5.2.4 동적 퀀텀 커플링
* 통신 : 동기 / 비동기
* 일관성 : consistency level
* 조정 : ochestrator, choreography

## 5.3 계약
* 아키텍처를 이루는 각 부분이 서로 연결되는 방식을 포괄적으로 의미한다
  * 아키텍처의 일부에서 정보 또는 의존성을 전달하는 용도로 쓰이는 일정한 양식
  * > API document가 contract의 일종으로 볼 수 있을듯
* 계약에는 엄격 / 느슨한 계약이 있다
  * 엄격 : xml/json schema, object, PRC
  * 보통 : GraphQL, REST
  * 느슨 : value, json, map
* 엄격한 계약은 이름,타입, 순서등 모든 것을 준수하며 모호함을 남기지 않는다
  * 통합 아키텍처의 취약점으로 발전할 위험이 있으므로 가급적 피하는 것이 좋다
* 보통 계약은 추가 정보가 기존 정보를 깨뜨리지 않는다
  * > JsonIgnore?
  * 언젠가 필요할 것이라는 짐작으로 미리 정보를 포함시키면 Stamp coupling 이라는 안티패턴에 빠진다
  * > 빈번한 무논리인데, 반박할 수 있는 좋은 이론인듯
  * 의미론적 커플링과 필수 정보 사이에서 균형을 유지할 수 있고 취약점 노출까지 방지할 수 있다
* 느슨한 계약은 마이크로서비스 아키텍처의 주요 목표인 극도로 분리된 시스템을 구축할 수 있다
  * 확신과 검증의 부재, 애플리케이션 로직 증가 등의 트레이드 오프를 동반한다
  * > 아무거나 써서 메모장 처럼 사용할수도 있음

### 5.3.1 진화적 마이크로서비스 아키텍처
* 마이크로서비스 아키텍처는 아키텍처 요소 사이에 물리적 bounded context를 정의하고
변경 가능성이 있는 모든 부분을 캡슐화한다
  * 서비스의 전달 기능에 기여하는 모든 요소가 bounded context안에 담긴다
* 개발자들이 선택한 아키텍처 패턴과 무관하게 아키텍트는 명시적으로 퀀텀의 크기를 정의해야 한다
  * 퀀텀의 크기가 아키텍처 내부에서 발생할 점진적 변화의 하한을 결정한다

---

* 계층 아키텍처는 주로 애플리케이션의 기술적 차원과 작동 원리에 초점을 맞춘다
* 결제라는 bounded context가 있다면 어디에 위치할까
  * 계층 아키텍처는 도메인 개념을 수용하게 설계되지 않았기 때문에 
여러 계층에 걸쳐서 존재하게 된다
  * 개발자는 도메인 레벨의 변경 발생 시 모든 계층을 수정해야 한다

---
* bounded context로 분할된 마이크로 서비스 아키텍처는 어떨까
* 결제를 변경한다면 결제 서비스만 수정하면 될 것

---
* 마이크로서비스 아키텍처는 일반적으로 다음 7원칙을 따른다

1. 비즈니스 도메인 중심 모델링
  * 단순히 작은 서비스를 만드는 것이 아니라 쓸모 있는 bounded context를 만드는것
2. 세부 구현 은닉
  * 마이크로 서비스의 기술 아키텍처는 비즈니스 도메인을 기준으로 세워진 서비스 경계 내부에 캡슐화 된다
3. 자동화 문화
  * CI/CD
4. 고도의 분산성
  * 결합보다는 중복을 선호한다
  * 이름이 같고 속성이 비슷한 개념을 개발자는 하나로 만들어 재사용하고 시간과 노력을 절약하려 한다
  * 그러나 이것은 공유 컴포넌트를 사용하는 모든 팀에 변경 사항이 전파되어야 하므로 오히려 더 힘들 수 있다
5. 배포 독립성
  * 각 서비스 컴포넌트를 독립적으로 배포함으로 bounded context를 물리적으로 표현
6. 장애 격리
   * 컨텍스트 내부 장애와 서비스 조율 과정의 모든 장애를 격리해야한다
7. high observable
  * 모니터링과 로깅은 아키텍처의 최우선 관심사여야 한다
  * 운영팀이 모니터링 못하는 서비스는 없는 것이나 마찬가지다

---
* 마이크로 서비스의 아키텍처 퀀텀은 곧 서비스이다
* 점진적 변화
  * 각 서비스는 도메인 개념에 맞춰 bounded context를 형성하므로
  변화의 범위는 context에 한정된다
* 피트니스 함수를 이용한 변화 유도
  * 각 서비스의 경계가 명확하므로 쉽게 피트니스 함수를 구축할 수 있다

## 5.4 재사용 패턴
* 코드 재사용은 오남용으로 인해 문제를 만들기도 한다
  * 소프트웨어 재사용은 레고 블록 조립이 아닌 장기 이식에 가깝다. !!!
* 개발자들이 코드의 재사용성을 높이기 위해 노력할수록 사용성은 낮아진다
  * 다양한 사례에 대응하기 위한 option / condition 추가
* 마이크로 서비스는 코드 재사용을 자제하지만 커플링보다는 중복을 선호하는 철학을 따른다

### 5.4.1 효과적인 재사용 = 추상화 + 낮은 변동성
* 많은 아키텍트가 직면한 과제는 완전한 재사용과 bounded context의 분리이다

### 5.4.2 사이드카 및 서비스 메시 : 직교 운영 커플링
* 마이크로 서비스에서는 많은 경우 결합보다는 중복을 선택한다
* 그런데 모니터링, 로깅, 인증 등도 그럴까
  * 이들은 오히려 커플링인 편이 이득이다
  * 각자 구현한다면 표준을 어떻게 확인할까 업그레이드는?
* 사이드카 패턴은 이 문제를 우아하게 해결할 수 있는 대응책이 된다
* hexagonal architecture 의 중심에 비즈니스 로직을 두고 
* 다른 생태계들이 이를 감싼다, 각 요소들은 어댑터를 통해 끼워넣는다
> k8s에 demonset?
* 사이드카를 이용하면 아키텍처 전체를 관통하는 관심사를 하나의 일관성 있는 계층으로 고립시킬 수 있다

### 5.4.3 데이터 메시 : 직교 데이터 커플링
* 데이터 메시 : 분산 처리를 적용해 분석 데이터를 공유, 접근, 관리하는 기법
* 아래 원칙을 기반으로 성립된다
  * 데이터의 도메인 소유권
    * 소유권은 가장 친숙한 도메인이 가진다
    * 출처 또는 일급 소비자가 소유하고 공유한다
    * 데이터 웨어하우스나 레이크는 중간 변환 단계를 거쳐 데이터를 제공하지만
    데이터 메시 아키텍처는 여러 도메인에서 P2P 방식으로 분산 공유하거나 접근할 수 있다
  * 제품으로서의 데이터
    * 고립을 방지하고 공유 장려를 위해 데이터에 제품의 개념을 도입한다
    * 데이터 제품 퀀텀의 목표는 안전하고 품질 높은 데이터를 적시에 제공하며, 소비자가 쉽게 발견하고
    이해할 수 있도록 관리하는 것이다
  * 자가 서비스 데이터 플랫폼
    * 도메인팀이 제품을 구축하고 유지 관리할 수 있도록 자가 서비스 플랫폼 기능을 제공한다
    * 데이터 제품의 선언적 생성, 검색 및 브라우징을 이용한 메시 전체 데이터의 검색 가능성,
    데이터 계보 등의 지능형 그래프 생성 등이 있다
  * 전산 연합 거버넌스
    * 데이터의 분산된 소유권을 극복하고 조직 전체의 거버넌스 요구 사항이 모든 도메인에서 일괄적으로 충족되도록 보장한다
    * 컴플라이언스, 보안, 개인정보보호 등
    * 채택된 정책은 자동화를 거쳐 모든 데이터 제품에 내장된다

---
chat gpt said


데이터 메시는 분석 데이터를 분산 처리하여 공유, 접근, 관리하는 새로운 아키텍처 패턴입니다. 이 아이디어를 좀 더 쉽게 이해하기 위해서는 몇 가지 주요 원칙을 알아봐야 합니다:

1. 데이터의 도메인 소유권:
* 데이터는 가장 잘 알고 있는 도메인이 소유해야 합니다. 예를 들어, 고객 데이터는 고객 관리 팀이 소유하게 됩니다.
이러한 방식은 데이터 웨어하우스나 레이크에서 중앙 집중적으로 관리하는 대신 여러 도메인 간에 데이터를 직접 공유하거나 접근하는 방식으로 동작합니다.
2. 제품으로서의 데이터:
* 데이터를 단순히 정보의 집합이 아닌, '제품'으로 보아야 합니다. 즉, 데이터의 품질, 접근성 및 가용성에 대한 책임을 가져야 합니다.
목표는 데이터를 안전하게, 높은 품질로, 적시에 제공하면서 사용자가 쉽게 찾고 이해할 수 있게 만드는 것입니다.
3. 자가 서비스 데이터 플랫폼:
* 각 도메인 팀이 스스로 데이터 제품을 만들고 관리할 수 있도록 도와주는 플랫폼이 필요합니다.
이 플랫폼은 데이터 제품의 생성부터 검색, 그리고 다른 데이터 제품과의 연결성을 파악하기 위한 기능들을 제공합니다.
4. 전산 연합 거버넌스:
* 데이터가 여러 도메인에 분산되어 있기 때문에, 전체 조직의 데이터 관리 원칙이나 정책이 일관되게 적용되어야 합니다. 이를 통해 데이터의 품질과 보안 등의 중요한 요소들이 유지될 수 있습니다.

* 간단히 말하면, 데이터 메시는 데이터를 여러 도메인에 분산시켜 관리하되, 그 데이터를 '제품'처럼 취급하며, 각 도메인 팀이 스스로 해당 데이터 제품을 관리하게끔 도와주는 패턴입니다. 이를 통해 조직 전체에서 데이터의 품질과 사용성을 높이려는 목표를 추구합니다.

---
* 데이터 제품 퀀텀(DPQ)
  * 현대의 아키텍처는 일반적으로 다음과 같은 유형의 DPQ를 보유한다
  * 원천 DPQ
    * 협업 대상 아키텍처 퀀텀을 대신해 분석 데이터 제공
  * 집계 DPQ
    * 데이터를 집계한다, 비동기가 아닌 경우 동기 쿼리 방식으로 조회하기도 한다
  * 목적 DPQ
    * 분석 보고서, bi, 머신러닝 등 특정 요구 사항에 대응하는 DPQ
