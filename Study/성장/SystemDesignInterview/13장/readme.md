# 13장 검색어 자동완성 시스템
## 1단계 문제 이해 및 설계 범위 확정
* 자동완성은 첫번째 부분으로 한정
* 5개의 검색어가 표시되어야 함
* 빈도에 따른 인기순
* 다국어 지원(extension)
* 모든 query는 영어 소문자
* DAU 10,000,000

### 요구사항 재정의
* 응답속도는 100ms 이내여야 불편함을 겪지 않는다.
* 입력한 단어와 연관된 것이어야 한다
* 순위 모델에 따라 정렬되어야 한다
* 확장이 가능하다
* 시스템 일부의 장애가 전체 시스템으로 확산되지 않는다

### 개략적 규모 추정
* 1천만 사용자가 매일 10건 검색 = 1억회
* 5바이트 4개 단어를 이용하므로 20바이트를 평균 사용한다
* QPS는 약 24,000 (1억회 * 20바이트 / 86400초)
* 최대 48,000
* 20%는 신규 검색어로 가정하여 20억 바이트 * 0.2 = 0.4GB의 신규 데이터가 추가됨

## 2단계 개략적 설계안 제시 및 동의 구하기
> 시스템은 크게 두 부분으로 나눈다
* 사용자의 query를 실시간으로 수집하는 데이터 수집 서비스
* query에 대한 5개의 인기 검색어를 정렬해 주는 query 서비스

### 데이터 수집 서비스
twitch -> twitter -> twitter -> twillo로 검색했다면

|query|빈도|
|---|---|
|twitch|1|
|twitter|2|
|twillo|1|

### query 서비스
query문의 빈도를 저장한다

| query     | frequency |
|-----------|-----------|
| twitter   | 25        |
| twitch    | 29        |
| twilight | 25        |
|...|...|

사용자가 tw..를 검색했다면 아래와 같은 형태로 db에 query할 수 있다
```SQL
SELECT * FROM frequncy_table
WHERE query LIKE 'prefix%'
ORDER BY frequency DESC
LIMIT 5
```

사용자 호출이 적을때는 괜찮지만 호출이 많아진다면 db가 병목이 될 수 있다

## 3단계 상세 설계

### trie 자료구조
* prefix tree
* 단어를 tree로 만들어 저장하고 child node의 끝에 frequency를 저장
* 최악의 경우 전체 tree를 모두 검색해야 할 수 있음
  * 문제를 막기위한 방법
    * 최대 길이 제한
    * 부모 노드에 빈도를 caching

### 데이터 수집 서비스
* 실시간 데이터 수정은 좋은 방법이 아니다
  * 매번 캐싱을 하면 query 서비스가 느려진다
  * 인기 검색어의 순위는 자주 변경되지 않을 가능성이 높다
* 따라서 로그를 통해 trie를 업데이트 하는 시스템을 구축한다.

1. 입력에 따라 로그를 생산하고
2. 생상된 로그를 aggregation 하는 서버로 모은다
   3. 필요한 실시간성에 따라 업데이트 주기를 결정한다
4. 취합된 데이터를 작업 서버를 통해 trie로 업데이트 한다
5. trie cache에 업데이트 한다
6. trie cache에 업데이트 한 데이터를 trie db에 업데이트 한다
   7. 주기적으로 trie를 db에 저장한다
   8. trie를 inverted index로 만들어서 테이블로 검색할 수 있게 만든다

### query 서비스
1. query가 lb로 전달된다
2. lb는 api서버로 보낸다
3. api 서버는 trie 캐시로 응답을 구성한다
4. miss인 경우 db에서 가져와 업데이트 한다